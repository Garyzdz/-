‘’‘
定义：训练集上效果好，测试集上效果差的问题；数学上表现为：低偏差，高方差。

解决方案：1、正则化：L1正则化，L2正则化，矩阵正则化“费罗贝尼乌斯范数”
         正则化的本质是：惩罚权重系数W
         
         L1范数是指向量中各个元素绝对值之和。具有稀疏效果，参数中0增多，实际上内存并没有多少减少。
         
         L2范数是指距离范数，使得各个参数都趋向与0，由约束组成圆的半径决定；正式由于参数小的原因，解决了因为部分参数太大导致的过拟合问题。
         即：W的变化范围变小，那么 Z = WX + b 的值也被约束的变小，在激活函数中小范围的变化可以近似为线性拟合，所以不会过拟合。
         
         
         2、dropout随机丢弃
         设置概率，使一些神经元随机失活；由于所有神经元都有失活的风险，所以会抑制大权重的出现，与L2正则化类似。
         
         
         3、数据增强
         数据扩增：翻转、平移、裁剪、强变形
         早停：训练loss下降，测试集却上升时。
         
         


’‘’
